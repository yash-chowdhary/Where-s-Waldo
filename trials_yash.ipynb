{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cyvlfeat as vlfeat\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "import os.path as osp\n",
    "from skimage import filters\n",
    "from skimage.feature import corner_peaks\n",
    "from skimage.io import imread\n",
    "import pickle\n",
    "from random import shuffle\n",
    "from scipy.spatial.distance import cdist\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bags_of_sifts(image_paths=[], vocab_filename='', img=None):\n",
    "\n",
    "    with open(vocab_filename, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "\n",
    "    vocab_size = vocab.shape[0]\n",
    "#     print(vocab_size)\n",
    "    feats = []\n",
    "    \n",
    "    if len(image_paths) == 0:\n",
    "        image_paths = ['']\n",
    "    \n",
    "    for path in image_paths:\n",
    "        image = np.asarray(plt.imread(path)) if path != '' else img\n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        (frames, descriptors) = vlfeat.sift.dsift(img_gray, fast=True, step=10)\n",
    "        \n",
    "        samples = descriptors\n",
    "        \n",
    "        D = cdist(samples, vocab)\n",
    "        \n",
    "        closest_words = np.argmin(D, axis=1)\n",
    "\n",
    "#         for i in range(D.shape[0]):\n",
    "#             min_index = np.argmin(D[i])\n",
    "#             histogram[min_index]+=1\n",
    "\n",
    "        histogram, bin_edges = np.histogram(closest_words, bins=np.arange(0, vocab_size+1))\n",
    "#         print(histogram)\n",
    "\n",
    "        if np.linalg.norm(histogram) == 0.0:\n",
    "            print(descriptors.shape)\n",
    "            print(D.shape)\n",
    "            print(np.linalg.norm(histogram))\n",
    "            print(img_gray.shape)\n",
    "            print(\"--\")\n",
    "            \n",
    "            \n",
    "        histogram = histogram / np.linalg.norm(histogram)\n",
    "        feats.append(histogram)\n",
    "        \n",
    "    N = len(image_paths)\n",
    "    d = vocab_size\n",
    "    feats = np.asarray(feats)\n",
    "    feats = feats.reshape((N,d))\n",
    "    return feats\n",
    "\n",
    "\n",
    "def build_vocabulary(image_paths, vocab_size):\n",
    "    dim = 128     \n",
    "    vocab = np.zeros((vocab_size,dim))\n",
    "    sift_features = []\n",
    "\n",
    "    for path in image_paths:\n",
    "        image = np.asarray(plt.imread(path))\n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        (frames, descriptors) = vlfeat.sift.dsift(img_gray, fast=True, step=5)\n",
    "\n",
    "        samples = np.random.permutation(descriptors)[:20]\n",
    "\n",
    "        for descriptor in samples:\n",
    "            sift_features.append(descriptor)\n",
    "\n",
    "    sift_features = np.asarray(sift_features).astype('float64').reshape((-1,128))\n",
    "    vocab = vlfeat.kmeans.kmeans(sift_features, vocab_size)\n",
    "\n",
    "    return vocab\n",
    "\n",
    "clf = LinearSVC(C=2)\n",
    "\n",
    "def svm_classify(train_image_feats, train_labels, test_image_feats):\n",
    "    categories = list(set(train_labels))\n",
    "    test_labels = []\n",
    "    \n",
    "    clf.fit(train_image_feats, train_labels)\n",
    "    test_labels = clf.predict(test_image_feats)\n",
    "\n",
    "    return test_labels\n",
    "\n",
    "\n",
    "def test_accuracy(test_labels, predicted_labels):\n",
    "    num_correct = 0\n",
    "    for i,label in enumerate(test_labels):\n",
    "        if (predicted_labels[i] == label):\n",
    "            num_correct += 1\n",
    "    return num_correct/len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "43\n",
      "27\n",
      "184\n"
     ]
    }
   ],
   "source": [
    "waldo_paths = []\n",
    "wenda_paths = []\n",
    "wizard_paths = []\n",
    "negative_paths = []\n",
    "all_paths = []\n",
    "\n",
    "test_image_paths = []\n",
    "with open('datasets/ImageSets/val.txt') as file:\n",
    "    for img_id in file.readlines():\n",
    "        img_id = img_id.rstrip()\n",
    "        test_image_paths.append('datasets/JPEGImages/{}.jpg'.format(img_id))\n",
    "\n",
    "file.close()\n",
    "\n",
    "\n",
    "template_dirs = [\"templates/waldo\",\"templates/wenda\",\"templates/wizard\"]\n",
    "\n",
    "for i in range(len(template_dirs)):\n",
    "    for img_id in os.listdir(template_dirs[i]):\n",
    "        path_to_dir = os.path.join(template_dirs[i], '{}'.format(img_id)).rstrip()\n",
    "        if not os.path.isdir(path_to_dir):\n",
    "            continue\n",
    "        list_of_files = os.listdir(path_to_dir)\n",
    "        for file_name in list_of_files:\n",
    "            all_paths.append(os.path.join(path_to_dir, '{}'.format(file_name)).rstrip())\n",
    "            if i==0:\n",
    "                waldo_paths.append(os.path.join(path_to_dir, '{}'.format(file_name)).rstrip())\n",
    "            if i==1:\n",
    "                wenda_paths.append(os.path.join(path_to_dir, '{}'.format(file_name)).rstrip())\n",
    "            if i==2:\n",
    "                wizard_paths.append(os.path.join(path_to_dir, '{}'.format(file_name)).rstrip())\n",
    "\n",
    "negative_dir = \"negatives_same_scale\"\n",
    "\n",
    "for file_name in os.listdir(negative_dir):\n",
    "    path = os.path.join(negative_dir, '{}'.format(file_name)).rstrip()\n",
    "    negative_paths.append(path)\n",
    "    all_paths.append(path)\n",
    "\n",
    "# print(sorted(all_paths))\n",
    "print(len(waldo_paths))\n",
    "print(len(wenda_paths))\n",
    "print(len(wizard_paths))\n",
    "print(len(negative_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the BAG-OF-SIFT representation for images\n",
      "False\n",
      "vocab.pkl saved\n"
     ]
    }
   ],
   "source": [
    "# get vocab\n",
    "print('Using the BAG-OF-SIFT representation for images')\n",
    "\n",
    "vocab_filename = 'vocab.pkl'\n",
    "\n",
    "# print('No existing visual word vocabulary found. Computing one from training images')\n",
    "vocab_size = 200  # Larger values will work better (to a point) but be slower to compute\n",
    "vocab = build_vocabulary(all_paths,vocab_size)\n",
    "print(np.isnan(vocab).any())\n",
    "    \n",
    "with open(vocab_filename, 'wb') as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "    print('{:s} saved'.format(vocab_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_feats = 391\n",
      "--\n",
      "test_feats_lengths\n",
      "--\n",
      "test_labels lengths\n",
      "80\n",
      "311\n",
      "311\n",
      "--\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "#get bags of sifts\n",
    "template_percentage = 0.8\n",
    "\n",
    "print(f\"all_feats = {len(all_paths)}\")\n",
    "\n",
    "# waldo_feats = bags_of_sifts(waldo_paths,vocab_filename)\n",
    "# wenda_feats = bags_of_sifts(wenda_paths,vocab_filename)\n",
    "# wizard_feats = bags_of_sifts(wizard_paths,vocab_filename)\n",
    "\n",
    "# print(np.isnan(waldo_feats).any())\n",
    "# print(np.isnan(wenda_feats).any())\n",
    "# print(np.isnan(wizard_feats).any())\n",
    "\n",
    "# print(waldo_feats)\n",
    "# print(wenda_feats)\n",
    "# print(wizard_feats)\n",
    "\n",
    "\n",
    "waldo_feats = bags_of_sifts(waldo_paths[:int(len(waldo_paths)*template_percentage)],vocab_filename)\n",
    "wenda_feats = bags_of_sifts(wenda_paths[:int(len(wenda_paths)*template_percentage)],vocab_filename)\n",
    "wizard_feats = bags_of_sifts(wizard_paths[:int(len(wizard_paths)*template_percentage)],vocab_filename)\n",
    "negative_feats = bags_of_sifts(negative_paths[:int(len(negative_paths)*template_percentage)], vocab_filename)\n",
    "\n",
    "training_feats = []\n",
    "training_feats.extend(waldo_feats)\n",
    "training_feats.extend(wenda_feats)\n",
    "training_feats.extend(wizard_feats)\n",
    "training_feats.extend(negative_feats)\n",
    "\n",
    "# print(len(waldo_feats))\n",
    "# print(len(wenda_feats))\n",
    "# print(len(wizard_feats))\n",
    "print(\"--\\ntest_feats_lengths\")\n",
    "\n",
    "# test_image_feats \n",
    "waldo_test_feats = bags_of_sifts(waldo_paths[int(len(waldo_paths)*template_percentage):len(waldo_paths)],vocab_filename)\n",
    "wenda_test_feats = bags_of_sifts(wenda_paths[int(len(wenda_paths)*template_percentage):len(wenda_paths)],vocab_filename)\n",
    "wizard_test_feats = bags_of_sifts(wizard_paths[int(len(wizard_paths)*template_percentage):len(wizard_paths)],vocab_filename)\n",
    "negative_test_feats = bags_of_sifts(negative_paths[int(len(negative_paths)*template_percentage):len(negative_paths)],vocab_filename)\n",
    "\n",
    "test_feats = []\n",
    "test_feats.extend(waldo_test_feats)\n",
    "test_feats.extend(wenda_test_feats)\n",
    "test_feats.extend(wizard_test_feats)\n",
    "test_feats.extend(negative_test_feats)\n",
    "\n",
    "#set training labels\n",
    "train_labels = []\n",
    "train_labels.extend([0]*len(waldo_feats))\n",
    "train_labels.extend([1]*len(wenda_feats))\n",
    "train_labels.extend([2]*len(wizard_feats))\n",
    "train_labels.extend([3]*len(negative_feats))\n",
    "\n",
    "# print(len(waldo_test_feats))\n",
    "# print(len(wenda_test_feats))\n",
    "# print(len(wizard_test_feats))\n",
    "print(\"--\\ntest_labels lengths\")\n",
    "\n",
    "ground_truth_test_labels = []\n",
    "ground_truth_test_labels.extend([0]*len(waldo_test_feats))\n",
    "ground_truth_test_labels.extend([1]*len(wenda_test_feats))\n",
    "ground_truth_test_labels.extend([2]*len(wizard_test_feats))\n",
    "ground_truth_test_labels.extend([3]*len(negative_test_feats))\n",
    "\n",
    "print(len(ground_truth_test_labels))\n",
    "\n",
    "print(len(train_labels))\n",
    "print(len(training_feats))\n",
    "print(\"--\")\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted_labels = svm_classify(training_feats, train_labels, test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.77996743e-01   2.19124160e-03   3.01638991e-03   1.16795659e-01]\n",
      " [  8.10314178e-01   1.29717410e-01   8.86325352e-03   5.11052050e-02]\n",
      " [  1.14402354e-01   8.76607239e-01   9.96555435e-04   7.99381733e-03]\n",
      " [  8.49645078e-01   2.69335206e-03   3.38097615e-03   1.44280568e-01]\n",
      " [  5.86937487e-01   2.90454496e-02   6.20405599e-02   3.21976483e-01]\n",
      " [  9.38659787e-01   5.53756719e-03   6.70831744e-03   4.90943044e-02]\n",
      " [  9.60931838e-01   2.15911982e-03   3.51157319e-03   3.33975069e-02]\n",
      " [  8.85311663e-01   6.58615604e-02   6.29082881e-03   4.25359681e-02]\n",
      " [  7.13811755e-01   5.26387766e-02   6.13070279e-03   2.27418751e-01]\n",
      " [  8.27072561e-01   1.32443324e-01   3.14412685e-03   3.73399928e-02]\n",
      " [  9.01323318e-01   3.46054486e-03   6.28790446e-03   8.89282152e-02]\n",
      " [  3.22241843e-01   5.99874198e-01   2.61698794e-02   5.17140999e-02]\n",
      " [  8.55000377e-01   2.16712127e-03   8.52029712e-04   1.41980484e-01]\n",
      " [  9.05604899e-01   3.46444221e-03   9.15406831e-03   8.17765743e-02]\n",
      " [  3.16589504e-01   2.17327848e-01   3.93670529e-01   7.24120960e-02]\n",
      " [  2.92884707e-01   5.98386288e-01   6.94799200e-02   3.92490439e-02]\n",
      " [  9.52666938e-01   1.51739223e-03   2.15430791e-03   4.36613820e-02]\n",
      " [  5.00564575e-01   2.33660471e-02   1.01422733e-02   4.65927064e-01]\n",
      " [  4.57268000e-01   8.39603022e-02   5.16526476e-02   4.07119036e-01]\n",
      " [  3.79110962e-01   3.05408120e-01   7.59851485e-02   2.39495724e-01]\n",
      " [  9.79566991e-01   1.64694525e-03   1.33504136e-03   1.74510144e-02]\n",
      " [  1.05894066e-01   1.21669946e-02   7.66083181e-01   1.15855739e-01]\n",
      " [  5.02586484e-01   6.11226931e-02   7.18046166e-03   4.29110378e-01]\n",
      " [  4.67822880e-01   7.16207325e-02   1.62031293e-01   2.98525035e-01]\n",
      " [  7.44244695e-01   5.73799945e-03   2.07383977e-03   2.47943491e-01]\n",
      " [  7.19510078e-01   2.70981520e-01   4.92491527e-03   4.58350917e-03]\n",
      " [  6.85308039e-01   1.62762180e-01   5.08912764e-02   1.01038523e-01]\n",
      " [  6.19315088e-01   7.10508134e-03   9.97015648e-03   3.63609642e-01]\n",
      " [  5.97460449e-01   8.12234581e-02   4.98743914e-02   2.71441668e-01]\n",
      " [  6.43618464e-01   2.33166695e-01   9.90379974e-02   2.41768192e-02]\n",
      " [  5.68336397e-02   1.62054047e-01   7.13465130e-03   7.73977697e-01]\n",
      " [  2.96630591e-01   6.16976023e-01   1.44998971e-02   7.18934909e-02]\n",
      " [  2.10212171e-01   6.88178420e-01   5.62789012e-03   9.59814936e-02]\n",
      " [  6.69745743e-01   4.39869873e-02   5.35148475e-03   2.80915856e-01]\n",
      " [  8.95411789e-01   2.25640386e-02   9.72593948e-03   7.22982883e-02]\n",
      " [  7.35691488e-01   1.04884006e-01   2.57459190e-02   1.33678615e-01]\n",
      " [  3.00321072e-01   6.52998567e-01   6.13878109e-03   4.05415222e-02]\n",
      " [  1.62484378e-01   4.27156165e-02   4.34305489e-01   3.60494524e-01]\n",
      " [  4.72933888e-01   5.36466762e-03   5.23535125e-02   4.69347894e-01]\n",
      " [  5.27521849e-01   2.26320438e-02   3.57481316e-02   4.14097935e-01]\n",
      " [  3.28582466e-01   9.91760101e-03   5.92362247e-02   6.02263689e-01]\n",
      " [  5.43947071e-02   6.28318042e-02   6.83556497e-03   8.75937939e-01]\n",
      " [  2.04199016e-01   1.28646314e-01   3.89863402e-01   2.77291268e-01]\n",
      " [  2.05258816e-01   3.92785249e-03   4.66455612e-03   7.86148727e-01]\n",
      " [  3.47464621e-01   3.34258340e-02   2.58368161e-02   5.93272686e-01]\n",
      " [  9.02751982e-02   2.77295965e-03   3.74408648e-03   9.03207779e-01]\n",
      " [  4.01048809e-02   1.10977758e-02   1.49844624e-02   9.33812857e-01]\n",
      " [  4.26059067e-02   6.33722683e-03   4.42838203e-03   9.46628511e-01]\n",
      " [  6.28531948e-02   8.52789730e-03   1.82166584e-02   9.10402179e-01]\n",
      " [  1.10404499e-01   1.83796007e-02   9.53092705e-03   8.61685038e-01]\n",
      " [  1.33849373e-02   2.31432263e-02   5.80632174e-03   9.57665503e-01]\n",
      " [  9.50730871e-03   9.21763387e-03   1.66319637e-03   9.79611814e-01]\n",
      " [  1.02635466e-01   2.10861000e-03   1.58517447e-03   8.93670678e-01]\n",
      " [  2.98874438e-01   1.05661051e-02   1.80197693e-03   6.88757479e-01]\n",
      " [  1.55239210e-01   6.80265948e-03   2.58083781e-03   8.35377276e-01]\n",
      " [  6.01541638e-01   2.50006557e-01   5.29363193e-03   1.43158183e-01]\n",
      " [  2.94895887e-01   2.18795557e-02   1.45974159e-01   5.37250400e-01]\n",
      " [  1.64291546e-01   3.32113393e-02   5.95561385e-01   2.06935748e-01]\n",
      " [  2.57033616e-01   5.60490847e-01   1.11943847e-02   1.71281114e-01]\n",
      " [  7.88154975e-02   8.19463611e-01   3.78594808e-02   6.38613850e-02]\n",
      " [  1.17297053e-01   1.08609842e-02   6.91221237e-01   1.80620670e-01]\n",
      " [  3.40267003e-01   1.87037401e-02   2.65156299e-01   3.75872940e-01]\n",
      " [  1.26273900e-01   3.54604004e-03   1.09741669e-02   8.59205961e-01]\n",
      " [  2.60382146e-01   3.21911387e-02   2.75358111e-02   6.79890931e-01]\n",
      " [  3.19526196e-02   5.31542040e-02   1.24048404e-01   7.90844738e-01]\n",
      " [  4.30921502e-02   4.34026569e-02   6.27204496e-03   9.07233179e-01]\n",
      " [  4.25212830e-02   6.27072304e-02   3.91113525e-03   8.90860319e-01]\n",
      " [  5.49511574e-02   5.45590511e-03   2.46256380e-03   9.37130332e-01]\n",
      " [  4.71694879e-02   1.30991554e-02   1.02914115e-02   9.29439902e-01]\n",
      " [  5.99504173e-01   8.69324356e-02   4.43878062e-02   2.69175529e-01]\n",
      " [  3.50758433e-01   6.25865487e-03   3.36333644e-03   6.39619589e-01]\n",
      " [  6.19488247e-02   2.51074672e-01   7.34976726e-03   6.79626703e-01]\n",
      " [  7.58093894e-02   1.76796749e-01   4.92410399e-02   6.98152781e-01]\n",
      " [  1.43086731e-01   8.24351460e-02   1.79048181e-02   7.56573319e-01]\n",
      " [  1.10296845e-01   7.70513946e-03   8.04004297e-02   8.01597595e-01]\n",
      " [  9.38368216e-02   1.07172774e-02   8.73207599e-02   8.08125138e-01]\n",
      " [  1.17708527e-01   1.90740649e-03   1.35489106e-01   7.44894981e-01]\n",
      " [  4.12730813e-01   3.75048257e-02   2.10868344e-02   5.28677523e-01]\n",
      " [  6.11011147e-01   2.83701681e-02   1.33363521e-02   3.47282350e-01]\n",
      " [  1.07411504e-01   2.52136448e-03   1.82313435e-02   8.71835828e-01]]\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(learning_rate=0.01, \n",
    "                      objective='multi:softprob', \n",
    "                      n_estimators=2000, \n",
    "                      max_depth=3, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=1, \n",
    "                      num_class=4)\n",
    "model.fit(np.asarray(training_feats), np.asarray(train_labels))\n",
    "predicted = model.predict_proba(np.asarray(test_feats))\n",
    "print(predicted)\n",
    "# print(test_accuracy(ground_truth_test_labels, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725\n"
     ]
    }
   ],
   "source": [
    "# print(test_accuracy(ground_truth_test_labels, predicted_labels))\n",
    "\n",
    "# print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'kp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-959ac84f0a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0msliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-959ac84f0a1f>\u001b[0m in \u001b[0;36msliding_window\u001b[0;34m(window_x, window_y, step_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mct\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kp' is not defined"
     ]
    }
   ],
   "source": [
    "def svm_probability(train_image_feats, train_labels, test_image_feats):\n",
    "    categories = list(set(train_labels))\n",
    "    test_labels = []\n",
    "    \n",
    "    clf = SVC(C=2, gamma='scale',probability=True)\n",
    "    clf.fit(train_image_feats, train_labels)\n",
    "    test_probabilities = clf.predict_proba(test_image_feats)\n",
    "\n",
    "    return test_probabilities\n",
    "\n",
    "def sliding_window(window_x=200, window_y=600, step_size=1):\n",
    "    f = open('datasets/ImageSets/val.txt')\n",
    "    wa = open('my_waldo.txt', 'w+')\n",
    "    we = open('my_wenda.txt', 'w+')\n",
    "    wi = open('my_wizard.txt', 'w+')\n",
    "    \n",
    "    image_id = f.readline().rstrip()\n",
    "    image_id = '002'\n",
    "    while image_id:\n",
    "        image = np.asarray(plt.imread('datasets/JPEGImages/' + image_id + '.jpg'))\n",
    "        height, width, c = image.shape\n",
    "        \n",
    "        test_feats = []\n",
    "        \n",
    "#         print((height-window_size) * (width-window_size))\n",
    "#         print(f\"{height},{width}\")\n",
    "        \n",
    "        #get the keypoints of the image\n",
    "        #loop through these keypoints only => saves computation time\n",
    "        mser = cv2.MSER_create()\n",
    "#         img_gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        reg = mser.detectRegions(image)\n",
    "        print(len(reg))\n",
    "        \n",
    "        ct=0\n",
    "        for idx in range(len(kp)):\n",
    "            j,i = kp[idx].pt\n",
    "\n",
    "            i = int(np.round(i))\n",
    "            j = int(np.round(j))\n",
    "#             print(f\"{ct}. {i} {j}\")\n",
    "            \n",
    "            i_limit = i+window_y\n",
    "            j_limit = j+window_x\n",
    "            if i_limit >= height:\n",
    "                i_limit = height-1\n",
    "            if j_limit >= width:\n",
    "                j_limit = width-1\n",
    "            img = image[i:i_limit,j:j_limit]\n",
    "#             print(f\"{i}:{i_limit} {j}:{j_limit}\")\n",
    "            feats = bags_of_sifts(vocab_filename=vocab_filename, img=img)\n",
    "            test_feats.extend(feats)\n",
    "            ct += 1\n",
    "\n",
    "#         print(test_feats)\n",
    "#         print(\"--\")\n",
    "        \n",
    "        #hilda's code: sliding window along entire image\n",
    "#         test_feats=[]\n",
    "#         for i in range(0, height-window_size, step_size):\n",
    "#             for j in range(0, width-window_size, step_size):\n",
    "#                 img = image[i:i+window_size, j:j+window_size]\n",
    "#                 feats = bags_of_sifts(vocab_filename=vocab_filename, img=img)\n",
    "#                 test_feats.extend(feats)\n",
    "#                 if j==1: \n",
    "#                     break\n",
    "#             break\n",
    "\n",
    "#         print(len(test_feats))\n",
    "        predicted_probabilities = model.predict_proba(np.asarray(test_feats))\n",
    "#         print(predicted_probabilities)\n",
    "        locations = np.argmax(predicted_probabilities, axis=0)\n",
    "#         print(locations)\n",
    "        # hilda's code\n",
    "        conf = np.max(predicted_probabilities, axis=0)\n",
    "#         print(conf)\n",
    "\n",
    "        pl = model.predict(np.asarray(test_feats))\n",
    "        locations = np.where(pl == 0)[0]\n",
    "        \n",
    "        for k in range(len(locations)):\n",
    "            #hilda's code\n",
    "#             i = locations[k] // (height-window_size)\n",
    "#             j = locations[k] % (width-window_size)\n",
    "            j_new, i_new  = kp[locations[k]].pt  # x location of best-fit window of character k\n",
    "            \n",
    "            i_new = int(np.round(i_new))\n",
    "            j_new = int(np.round(j_new))\n",
    "#             print(f\"{locations[k]}. {i_new} {j_new}\")\n",
    "            i_limit_new = i_new+window_y\n",
    "            j_limit_new = j_new+window_x\n",
    "            \n",
    "            if i_limit_new >= height:\n",
    "                i_limit_new = height-1\n",
    "            if j_limit_new >= width:\n",
    "                j_limit_new = width-1\n",
    "            \n",
    "            patch = image[i_new:i_limit_new, j_new:j_limit_new]\n",
    "            plt.imshow(patch, interpolation='nearest')\n",
    "            plt.show()\n",
    "            \n",
    "#             res = image_id + ' ' + str(np.max(predicted_probabilities[locations[k]][k])) + ' ' + str(j_new) + ' ' + str(i_new) + ' ' + str(j_limit_new) + ' ' + str(i_limit_new) + '\\n'\n",
    "#             print(res)\n",
    "#             if k == 0:\n",
    "#                 wa.write(res)\n",
    "#             if k == 1:\n",
    "#                 we.write(res)\n",
    "#             if k == 2:\n",
    "#                 wi.write(res)\n",
    "        break\n",
    "        image_id = f.readline().rstrip()\n",
    "\n",
    "\n",
    "sliding_window(200, 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
